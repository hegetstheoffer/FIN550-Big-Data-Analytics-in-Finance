---
title: "Lecture 14"
subtitle: "Bagging, random forest, and boosting"


---

# Try it: load and inspect the Boston housing dataset

```{r, message=F}
library(tidyverse)
library(ggplot2)

# Housing information for 506 areas around Boston
housing <- read_csv('/Users/iveshe/Library/Mobile Documents/com~apple~CloudDocs/Term 1/FIN 550/Lec/lec-14/housing.csv')
nrow(housing)
ncol(housing)

# The data are complete, so no need to remove observations
sum(!complete.cases(housing))

```

---

# Try it: build a model of housing value

```{r}
summary(housing$MEDV)
# How many predictors are available?
num.p <- length(names(housing))-1
cat("\n")
print(paste("Number of predictors is:", num.p))
```

---


# Try it: estimate a tree model using bagging


```{r, message=F, eval=F}
library(randomForest)
set.seed(1)

# Importance = T: calculate how important each variable is
# For bagging, number of splits m=p
bag_housing <- randomForest(MEDV ~ ., data = housing, mtry = num.p, importance = TRUE)
bag_housing

```


---

# Try it: mean-squared error for "out-of-bag" observations


```{r, eval=F}
# B (number of trees)
bag_housing$ntree
# Number of times each observation is out-of-bag (OOB)
head(bag_housing$oob.times)
# On average, what fraction of the time is an observation OOB?
cat("\n")
mean(bag_housing$oob.times)/500
1/(exp(1))
```

```{r}
# Vector of OOB error (length=B)
round(head(bag_housing$mse),1)
# OOB error vs number of trees
plot(bag_housing)
```

```{r}
# Display in table form
importance(bag_housing)
```

```{r}
# Or, visualize using a plot
varImpPlot(bag_housing)
```


---


# Try it: estimate a tree model using random forest

```{r, eval=F}
# Set number of random splits equal to a value less than 12
rf_housing <- randomForest(MEDV ~ ., data = housing, mtry = 6, importance = TRUE)
rf_housing

```

```{r}
importance(rf_housing)
```

```{r}
# Or, visualize using a plot
varImpPlot(rf_housing)
```

```{r}
bag.mse <- bag_housing$mse
rf.mse <- rf_housing$mse
ntrees <- 1:bag_housing$ntree
df <- data.frame(ntrees = ntrees,
bag.mse = bag.mse,
rf.mse = rf.mse)
ggplot(df, aes(x=ntrees)) +
geom_line(aes(y=bag.mse),color="red") +
geom_line(aes(y=rf.mse),color="blue") +
ylab("Mean-squared Error") +
theme_bw() +
theme(axis.title=element_text(size=20))
```

```{r}
# Note: for classification, specify type="prob" (probability) or type="class" (mode)
housing$yhat.bag <- predict(bag_housing, housing)
housing$yhat.rf <- predict(rf_housing, housing)
# MSE
mean((housing$yhat.bag - housing$MEDV)^2)
mean((housing$yhat.rf - housing$MEDV)^2)
```

