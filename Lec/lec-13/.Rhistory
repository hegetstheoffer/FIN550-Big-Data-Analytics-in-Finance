library(tidyverse)
library(ggplot2)
# Housing information for 506 areas around Boston
housing <- read_csv('/Users/iveshe/Library/Mobile Documents/com~apple~CloudDocs/Term 1/FIN 550/Lec/lec-13/housing.csv') %>%
select(MEDV, CRIM, NOX, RM, TAX)
nrow(housing)
ncol(housing)
sum(!complete.cases(housing)) # Check for missing values
library(rpart)
library(rpart.plot)
# method="anova" for regression trees
# Set cp (alpha) equal to 0 to grow a full tree
# (Optional) set maxdepth=5 to limit how deep the tree is
set.seed(1)
tree_housing <- rpart(MEDV ~ ., data = housing, cp = 0,
maxdepth = 5, method = "anova")
# Plot the full tree
prp(tree_housing, box.palette = "auto")
# What does tree look like if you remove `maxdepth=5`?
library(rpart)
library(rpart.plot)
# method="anova" for regression trees
# Set cp (alpha) equal to 0 to grow a full tree
# (Optional) set maxdepth=5 to limit how deep the tree is
set.seed(1)
tree_housing <- rpart(MEDV ~ ., data = housing, cp = 0,
method = "anova")
# Plot the full tree
prp(tree_housing, box.palette = "auto")
# What does tree look like if you remove `maxdepth=5`?
library(rpart)
library(rpart.plot)
# method="anova" for regression trees
# Set cp (alpha) equal to 0 to grow a full tree
# (Optional) set maxdepth=5 to limit how deep the tree is
set.seed(1)
tree_housing <- rpart(MEDV ~ ., data = housing, cp = 0,
maxdepth = 5, method = "anova")
# Plot the full tree
prp(tree_housing, box.palette = "auto")
# What does tree look like if you remove `maxdepth=5`?
# Number of leaves/nodes
n_distinct(tree_housing$where) # `where` reports which leaf each obs was assigned to
# List variables that are most important for predicting outcomes
# Do these variables lie near the top or the bottom of the tree?
round(tree_housing$variable.importance,1)
cp <- printcp(tree_housing)
head(cp) # CP is alpha, xerror is CV MSE
cat("\n")
as.vector(cp[,1]) # set of alpha's considered by `rpart`
# Use cp object to identify minimum CV MSE
cvmse.min <-
# Use cp object to identify optimal alpha (hint: use `which.min()` to find the index)
index <-
alpha.best <-
print(paste("Min CV MSE is", cvmse.min))
# Use cp object to identify minimum CV MSE
cvmse.min <- min(cp[ , "xerror"])
# Use cp object to identify optimal alpha (hint: use `which.min()` to find the index)
index <- which.min(cp[ , "xerror"])
alpha.best <- cp[index,"CP"]
print(paste("Min CV MSE is", cvmse.min))
print(paste("Optimal alpha is", alpha.best))
df <- as.data.frame(cp)
ggplot(df, aes(x=-log(CP), y=xerror)) +
geom_point(size=2) +
theme_bw() +
theme(axis.title=element_text(size=24))+
theme(axis.text=element_text(size=20))+
geom_vline(xintercept =
-log(alpha.best))
prune_housing <- prune(tree_housing, cp = alpha.best)
# What happened to the number of leaves?
n_distinct(tree_housing$where)
n_distinct(prune_housing$where)
# Plot the pruned tree
prp(prune_housing, box.palette = "auto")
library(tidyverse)
library(rpart)
library(rpart.plot)
library(caret)
library(ggplot2)
# Load dataset
bank.df <- read_csv("/Users/iveshe/Library/Mobile Documents/com~apple~CloudDocs/Term 1/FIN 550/Lab/lab-13/UniversalBank.csv")
names(bank.df) <- gsub(" ", ".", names(bank.df))
# drop ID and zip code columns
bank.df <- bank.df %>% select(-ID, -ZIP.Code)
# convert numeric variables to categorical variables
bank.df$Personal.Loan <- as.factor(bank.df$Personal.Loan)
bank.df$Education <- as.factor(bank.df$Education)
str(bank.df)
# Build the tree
set.seed(1)
bank.tree <- rpart(Personal.Loan ~ ., data = bank.df, method = "class", cp = 0)
# Number of leaves
num_leaves <- sum(bank.tree$frame$var == "<leaf>")
print(paste("Number of leaves in the tree:", num_leaves))
prp(bank.tree, type = 1, extra = 1, under = TRUE, varlen = -10)
par(mar = c(5, 4, 4, 2) + 0.1)
plot(bank.tree, uniform = TRUE, main = "Classification Tree for Personal Loan", compress = TRUE, margin = 0.1)
text(bank.tree, use.n = TRUE, all = TRUE, cex = 0.4, pretty = 0)
cp.table <- bank.tree$cptable
# Minimum CV MSE
min_cv_mse <- min(cp.table[, "xerror"])
print(paste("Minimum CV MSE:", min_cv_mse))
# Optimal alpha
optimal_alpha <- cp.table[which.min(cp.table[, "xerror"]), "CP"]
print(paste("Optimal alpha:", optimal_alpha))
# Prune tree
pruned.tree <- prune(bank.tree, cp = optimal_alpha)
# Pruned tree plot
prp(pruned.tree, type = 1, extra = 1, under = TRUE, varlen = -10)
# Number of leaves
num_leaves_pruned <- sum(pruned.tree$frame$var == "<leaf>")
print(paste("Number of leaves in the pruned tree:", num_leaves_pruned))
# Prediction
set.seed(1)
yhat.tree <- predict(pruned.tree, bank.df, type = "class")
print(paste("Number of predictions:", length(yhat.tree)))
print(paste("Number of observations:", nrow(bank.df)))
# Confusion Matrix
cm.tree <- confusionMatrix(yhat.tree, bank.df$Personal.Loan)
print(cm.tree)
# Logistic regression
logit <- glm(Personal.Loan ~ ., data = bank.df, family = binomial)
# Logistic predictions
yhat.logit.prob <- predict(logit, bank.df, type = "response")
yhat.logit <- as.factor(ifelse(yhat.logit.prob > 0.5, 1, 0))
# Logit confusion matrix
cm.logit <- confusionMatrix(yhat.logit, bank.df$Personal.Loan)
print(cm.logit)
# Create a vector of predicted housing values
medv_predict <- predict(prune_housing, newdata = housing)
length(medv_predict)
nrow(housing)
# MSE
mean((medv_predict - housing$MEDV)^2)
