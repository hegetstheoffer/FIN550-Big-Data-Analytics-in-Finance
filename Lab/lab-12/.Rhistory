knitr::opts_chunk$set(warning=FALSE, message=FALSE)
library(glmnet)
install.packages("glmnet")
library(glmnet)
library(ggplot2)
library(tibble)
library(tidyr)
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
library(glmnet)
library(ggplot2)
library(tibble)
library(tidyr)
# load the data
# first six rows
# column names
# dimension
# number of rows with missing values
# remove rows with any missing values
# dimension
# number of missing values
# convert a data frame of predictors to a matrix and create dummy variables for character variables
# first six rows of x
# outcome variable
# fit a lasso regression model
# Display the sequence of lambda values
# Save the smallest, optimal, and largest lambdas
# Display plot of coefficients
betas=as.matrix(fit$glmnet.fit$beta)
# load the data
df <- read.csv("'/Users/iveshe/Library/Mobile Documents/com~apple~CloudDocs/Term 1/FIN 550/Lab/lab-12/Hitters.csv'")
# load the data
df <- read.csv('/Users/iveshe/Library/Mobile Documents/com~apple~CloudDocs/Term 1/FIN 550/Lab/lab-12/Hitters.csv')
# first six rows
head(df)
# column names
names(df)
# dimension
dim(df)
# number of rows with missing values
sum(is.na(df))
# remove rows with any missing values
df <- na.omit(df)
# dimension
dim(df)
# number of missing values
sum(is.na(df))
# convert a data frame of predictors to a matrix and create dummy variables for character variables
x <- model.matrix(Salary ~ 0 + ., data = df)
# first six rows of x
head(x)
# outcome variable
y <- df$Salary
# fit a lasso regression model
fit <- cv.glmnet(x, y, alpha = 1)
# Display the sequence of lambda values
fit$lambda
# Save the smallest, optimal, and largest lambdas
lambda.large <- max(fit$lambda)
lambda.best <- fit$lambda.min
lambda.small <- min(fit$lambda)
lambda.large
lambda.best
lambda.small
# Display plot of coefficients
betas <- as.matrix(fit$glmnet.fit$beta)
lambdas <- fit$lambda
names(lambdas) <- colnames(betas)
as.data.frame(betas) %>%
tibble::rownames_to_column("variable") %>%
pivot_longer(-variable) %>%
mutate(lambda = lambdas[name]) %>%
ggplot(aes(x = lambda, y = value, col = variable)) +
geom_line() +
scale_x_log10() +
labs(x = "Lambda (log scale)", y = "Coefficient Value", title = "Lasso Regression Coefficients as a Function of Lambda")
# Display plot of coefficients
betas <- as.matrix(fit$glmnet.fit$beta)
lambdas <- fit$lambda
betas_df <- as.data.frame(betas)
betas_df <- tibble::rownames_to_column(betas_df, "variable")
betas_long <- pivot_longer(betas_df, cols = -variable, names_to = "lambda", values_to = "value")
betas_long$lambda <- as.numeric(gsub("X", "", betas_long$lambda))
ggplot(betas_long, aes(x = lambda, y = value, color = variable)) +
geom_line() +
scale_x_log10() +
labs(x = "Lambda (log scale)", y = "Coefficient Value", title = "Lasso Regression Coefficients as a Function of Lambda")
# Display plot of coefficients
betas <- as.matrix(fit$glmnet.fit$beta)
lambdas <- fit$lambda
betas_df <- as.data.frame(betas)
betas_df <- tibble::rownames_to_column(betas_df, "variable")
betas_long <- pivot_longer(betas_df, cols = -variable, names_to = "lambda", values_to = "value")
betas_long$lambda <- as.numeric(lambdas[match(betas_long$lambda, colnames(betas))])
# Remove NA values introduced by coercion
betas_long <- na.omit(betas_long)
ggplot(betas_long, aes(x = lambda, y = value, color = variable)) +
geom_line() +
scale_x_log10() +
labs(x = "Lambda (log scale)", y = "Coefficient Value", title = "Lasso Regression Coefficients as a Function of Lambda")
# CV MSE for large, small, and best lambdas
mse.large <- mean((y - predict(fit, s = lambda.large, newx = x))^2)
mse.best <- mean((y - predict(fit, s = lambda.best, newx = x))^2)
mse.small <- mean((y - predict(fit, s = lambda.small, newx = x))^2)
mse.large
mse.best
mse.small
# Predict salaries and store in yhat
df$yhat <- predict(fit, s = lambda.best, newx = x)
# MSE of predictions
mse.predictions <- mean((df$Salary - df$yhat)^2)
mse.predictions
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
library(glmnet)
library(ggplot2)
library(tibble)
library(tidyr)
# load the data
df <- read.csv('/Users/iveshe/Library/Mobile Documents/com~apple~CloudDocs/Term 1/FIN 550/Lab/lab-12/Hitters.csv')
# first six rows
head(df)
# column names
names(df)
# dimension
dim(df)
# number of rows with missing values
sum(is.na(df))
# remove rows with any missing values
df <- na.omit(df)
# dimension
dim(df)
# number of missing values
sum(is.na(df))
# convert a data frame of predictors to a matrix and create dummy variables for character variables
x <- model.matrix(Salary ~ 0 + ., data = df)
# first six rows of x
head(x)
# outcome variable
y <- df$Salary
# fit a lasso regression model
fit <- cv.glmnet(x, y, alpha = 1)
# Display the sequence of lambda values
fit$lambda
# Save the smallest, optimal, and largest lambdas
lambda.large <- max(fit$lambda)
lambda.best <- fit$lambda.min
lambda.small <- min(fit$lambda)
lambda.large
lambda.best
lambda.small
# Display plot of coefficients
betas <- as.matrix(fit$glmnet.fit$beta)
lambdas <- fit$lambda
betas_df <- as.data.frame(betas)
betas_df <- tibble::rownames_to_column(betas_df, "variable")
betas_long <- pivot_longer(betas_df, cols = -variable, names_to = "lambda", values_to = "value")
betas_long$lambda <- as.numeric(lambdas[match(betas_long$lambda, colnames(betas))])
# Remove NA values introduced by coercion
betas_long <- na.omit(betas_long)
ggplot(betas_long, aes(x = lambda, y = value, color = variable)) +
geom_line() +
scale_x_log10() +
labs(x = "Lambda (log scale)", y = "Coefficient Value", title = "Lasso Regression Coefficients as a Function of Lambda")
# CV MSE for large, small, and best lambdas
mse.large <- mean((y - predict(fit, s = lambda.large, newx = x))^2)
mse.best <- mean((y - predict(fit, s = lambda.best, newx = x))^2)
mse.small <- mean((y - predict(fit, s = lambda.small, newx = x))^2)
mse.large
mse.best
mse.small
# Predict salaries and store in yhat
df$yhat <- predict(fit, s = lambda.best, newx = x)
# MSE of predictions
mse.predictions <- mean((df$Salary - df$yhat)^2)
mse.predictions
# Display plot of coefficients
betas <- as.matrix(fit$glmnet.fit$beta)
lambdas <- fit$lambda
betas_df <- as.data.frame(betas)
betas_df <- tibble::rownames_to_column(betas_df, "variable")
betas_long <- pivot_longer(betas_df, cols = -variable, names_to = "lambda", values_to = "value")
betas_long$lambda <- as.numeric(lambdas[match(betas_long$lambda, colnames(betas))])
# Remove NA values introduced by coercion
betas_long <- na.omit(betas_long)
# Improved visualization
ggplot(betas_long, aes(x = lambda, y = value, color = variable)) +
geom_line() +
scale_x_log10() +
labs(x = "Lambda (log scale)", y = "Coefficient Value", title = "Lasso Regression Coefficients as a Function of Lambda") +
theme_minimal() +
theme(legend.position = "bottom", legend.box = "horizontal", legend.title = element_blank(), plot.title = element_text(hjust = 0.5))
# Display plot of coefficients
betas <- as.matrix(fit$glmnet.fit$beta)
lambdas <- fit$lambda
betas_df <- as.data.frame(betas)
betas_df <- tibble::rownames_to_column(betas_df, "variable")
betas_long <- pivot_longer(betas_df, cols = -variable, names_to = "lambda", values_to = "value")
betas_long$lambda <- as.numeric(lambdas[match(betas_long$lambda, colnames(betas))])
# Remove NA values introduced by coercion
betas_long <- na.omit(betas_long)
# Improved visualization
ggplot(betas_long, aes(x = lambda, y = value, color = variable)) +
geom_line() +
scale_x_log10() +
labs(x = "Lambda (log scale)", y = "Coefficient Value", title = "Lasso Regression Coefficients as a Function of Lambda") +
theme_minimal() +
theme(legend.position = "right", legend.box = "vertical", legend.text = element_text(size = 8), legend.title = element_blank(), plot.title = element_text(hjust = 0.5))
# Display plot of coefficients
betas <- as.matrix(fit$glmnet.fit$beta)
lambdas <- fit$lambda
betas_df <- as.data.frame(betas)
betas_df <- tibble::rownames_to_column(betas_df, "variable")
betas_long <- pivot_longer(betas_df, cols = -variable, names_to = "lambda", values_to = "value")
betas_long$lambda <- as.numeric(lambdas[match(betas_long$lambda, colnames(betas))])
# Remove NA values introduced by coercion
betas_long <- na.omit(betas_long)
# Improved visualization
ggplot(betas_long, aes(x = lambda, y = value, color = variable)) +
geom_line() +
scale_x_log10() +
labs(x = "Lambda (log scale)", y = "Coefficient Value", title = "Lasso Regression Coefficients as a Function of Lambda") +
theme_minimal() +
theme(legend.position = "right", legend.box = "vertical", legend.text = element_text(size = 6), legend.title = element_blank(), plot.title = element_text(hjust = 0.5, size = 10))
# Display plot of coefficients
betas <- as.matrix(fit$glmnet.fit$beta)
lambdas <- fit$lambda
betas_df <- as.data.frame(betas)
betas_df <- tibble::rownames_to_column(betas_df, "variable")
betas_long <- pivot_longer(betas_df, cols = -variable, names_to = "lambda", values_to = "value")
betas_long$lambda <- as.numeric(lambdas[match(betas_long$lambda, colnames(betas))])
# Remove NA values introduced by coercion
betas_long <- na.omit(betas_long)
# Improved visualization
ggplot(betas_long, aes(x = lambda, y = value, color = variable)) +
geom_line() +
scale_x_log10() +
labs(x = "Lambda (log scale)", y = "Coefficient Value", title = "Lasso Regression Coefficients as a Function of Lambda") +
theme_minimal() +
theme(legend.position = "right", legend.box = "vertical", legend.text = element_text(size = 3), legend.title = element_blank(), plot.title = element_text(hjust = 0.5, size = 7))
# Display plot of coefficients
betas <- as.matrix(fit$glmnet.fit$beta)
lambdas <- fit$lambda
betas_df <- as.data.frame(betas)
betas_df <- tibble::rownames_to_column(betas_df, "variable")
betas_long <- pivot_longer(betas_df, cols = -variable, names_to = "lambda", values_to = "value")
betas_long$lambda <- as.numeric(lambdas[match(betas_long$lambda, colnames(betas))])
# Remove NA values introduced by coercion
betas_long <- na.omit(betas_long)
# Improved visualization
ggplot(betas_long, aes(x = lambda, y = value, color = variable)) +
geom_line() +
scale_x_log10() +
labs(x = "Lambda (log scale)", y = "Coefficient Value", title = "Lasso Regression Coefficients as a Function of Lambda") +
theme_minimal() +
theme(legend.position = "right", legend.box = "vertical", legend.text = element_text(size = 5), legend.title = element_blank(), plot.title = element_text(hjust = 0.5, size = 7))
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
library(glmnet)
library(ggplot2)
library(tibble)
library(tidyr)
# load the data
df <- read.csv('/Users/iveshe/Library/Mobile Documents/com~apple~CloudDocs/Term 1/FIN 550/Lab/lab-12/Hitters.csv')
# first six rows
head(df)
# column names
names(df)
# dimension
dim(df)
# number of rows with missing values
sum(is.na(df))
# remove rows with any missing values
df <- na.omit(df)
# dimension
dim(df)
# number of missing values
sum(is.na(df))
# convert a data frame of predictors to a matrix and create dummy variables for character variables
x <- model.matrix(Salary ~ 0 + ., data = df)
# first six rows of x
head(x)
# outcome variable
y <- df$Salary
# fit a lasso regression model
fit <- cv.glmnet(x, y, alpha = 1)
# Display the sequence of lambda values
fit$lambda
# Save the smallest, optimal, and largest lambdas
lambda.large <- max(fit$lambda)
lambda.best <- fit$lambda.min
lambda.small <- min(fit$lambda)
lambda.large
lambda.best
lambda.small
# Display plot of coefficients
betas <- as.matrix(fit$glmnet.fit$beta)
lambdas <- fit$lambda
betas_df <- as.data.frame(betas)
betas_df <- tibble::rownames_to_column(betas_df, "variable")
betas_long <- pivot_longer(betas_df, cols = -variable, names_to = "lambda", values_to = "value")
betas_long$lambda <- as.numeric(lambdas[match(betas_long$lambda, colnames(betas))])
# Remove NA values introduced by coercion
betas_long <- na.omit(betas_long)
# Improved visualization
ggplot(betas_long, aes(x = lambda, y = value, color = variable)) +
geom_line() +
scale_x_log10() +
labs(x = "Lambda (log scale)", y = "Coefficient Value", title = "Lasso Regression Coefficients as a Function of Lambda") +
theme_minimal() +
theme(legend.position = "right", legend.box = "vertical", legend.text = element_text(size = 5), legend.title = element_blank(), plot.title = element_text(hjust = 0.5, size = 7))
# CV MSE for large, small, and best lambdas
mse.large <- mean((y - predict(fit, s = lambda.large, newx = x))^2)
mse.best <- mean((y - predict(fit, s = lambda.best, newx = x))^2)
mse.small <- mean((y - predict(fit, s = lambda.small, newx = x))^2)
mse.large
mse.best
mse.small
# Predict salaries and store in yhat
df$yhat <- predict(fit, s = lambda.best, newx = x)
# MSE of predictions
mse.predictions <- mean((df$Salary - df$yhat)^2)
mse.predictions
# Display plot of coefficients
betas <- as.matrix(fit$glmnet.fit$beta)
lambdas <- fit$lambda
betas_df <- as.data.frame(betas)
betas_df <- tibble::rownames_to_column(betas_df, "variable")
betas_long <- pivot_longer(betas_df, cols = -variable, names_to = "lambda", values_to = "value")
betas_long$lambda <- as.numeric(lambdas[match(betas_long$lambda, colnames(betas))])
# Remove NA values introduced by coercion
betas_long <- na.omit(betas_long)
# Improved visualization
ggplot(betas_long, aes(x = lambda, y = value, color = variable)) +
geom_line() +
scale_x_log10() +
labs(x = "Lambda (log scale)", y = "Coefficient Value", title = "Lasso Regression Coefficients as a Function of Lambda") +
theme_minimal() +
theme(legend.position = "right", legend.box = "vertical", legend.text = element_text(size = 7), legend.title = element_blank(), plot.title = element_text(hjust = 0.5, size = 10))
# Display plot of coefficients
betas <- as.matrix(fit$glmnet.fit$beta)
lambdas <- fit$lambda
betas_df <- as.data.frame(betas)
betas_df <- tibble::rownames_to_column(betas_df, "variable")
betas_long <- pivot_longer(betas_df, cols = -variable, names_to = "lambda", values_to = "value")
betas_long$lambda <- as.numeric(lambdas[match(betas_long$lambda, colnames(betas))])
# Remove NA values introduced by coercion
betas_long <- na.omit(betas_long)
# Improved visualization
ggplot(betas_long, aes(x = lambda, y = value, color = variable)) +
geom_line() +
scale_x_log10() +
labs(x = "Lambda (log scale)", y = "Coefficient Value", title = "Lasso Regression Coefficients as a Function of Lambda") +
theme_minimal() +
theme(legend.position = "right", legend.box = "vertical", legend.text = element_text(size = 7), legend.title = element_blank(), plot.title = element_text(hjust = 0.5, size = 12))
# Display plot of coefficients
betas <- as.matrix(fit$glmnet.fit$beta)
lambdas <- fit$lambda
betas_df <- as.data.frame(betas)
betas_df <- tibble::rownames_to_column(betas_df, "variable")
betas_long <- pivot_longer(betas_df, cols = -variable, names_to = "lambda", values_to = "value")
betas_long$lambda <- as.numeric(lambdas[match(betas_long$lambda, colnames(betas))])
# Remove NA values introduced by coercion
betas_long <- na.omit(betas_long)
# Improved visualization
ggplot(betas_long, aes(x = lambda, y = value, color = variable)) +
geom_line() +
scale_x_log10() +
labs(x = "Lambda (log scale)", y = "Coefficient Value", title = "Lasso Regression Coefficients as a Function of Lambda") +
theme_minimal() +
theme(legend.position = "right", legend.box = "vertical", legend.text = element_text(size = 9), legend.title = element_blank(), plot.title = element_text(hjust = 0.5, size = 12))
